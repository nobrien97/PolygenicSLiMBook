---
title: "Running SLiM in Parallel"
author: "Nick O'Brien"
date: "06/05/2021"
output: html_document
css: styles.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 6.1 Overview

Now that we have an understanding of SLiM and a couple of models that might be useful, you're probably wondering - how can we actually run this in a manageable timeframe, and get a decent number of replicates? The answer is, however you want really. Whatever language you have that has a function to invoke system operating system commands (like ```system()``` in R) can probably be used to run SLiM remotely. In turn, you can get these calls to run sequentially or in parallel across cores on your machine, which will help negate some of the time needed to run many replicates. SLiM handles parallelism very well because it is written to only every use a single core: this means you can run separate SLiM experiments on each core your computer has available at the same time.

In this section, I'll go over how to run SLiM at the command line in a number of languages, and how to parallelise in each of them. I even provide a C++ implementation (TODO) which is overkill and not necessary at all, but it was fun to program (Remains to be seen)! 

Note that more information (and indeed some of the scripts you will see below are based upon these) is available at the [SLiM-Extras repository](https://github.com/MesserLab/SLiM-Extras) under 'sublaunching'


## 6.2 SLiM at the Command Line

To use SLiM from the command line, you simply call the ```slim``` command, followed by a path to a file. For example:

```{bash cmdslim, eval = F}
slim ~/Desktop/example_script.slim
```

This would run the script 'example_script.slim' with it's set parameters. Say you want to do some replicates. To do this you might want to change the random seed, which adjusts state of the random number generator that determines when, where, and how mutations, recombination, and mating between certain individuals might happen. You can do this using the ```-s``` flag:

```{bash cmdslim2, eval = F}
slim -s 123 ~/Desktop/example_script.slim
```

This would run the above script with the seed ```123```. Note that you shouldn't choose numbers like this, but instead use a random number generator to generate random numbers for you. 



Similarly, you can adjust parameters in your model with the ```-d``` flag, of which you can have as many as you want. For example, say you want to change the population size which is defined in your script as a parameter called ```Ne```. You could run:

```{bash cmdslim3, eval = F}
slim -s 123 -d Ne=1000 ~/Desktop/example_script.slim
```

Here, we've set Ne to be 1000, so ```slim``` will run the script with 1000 individuals and a seed of 123.

:::: {.extrabox data-latex=""}
::: {.center data-latex=""}
**Box 6.2.1**
:::
When it comes to random numbers, it comes as little surprise that humans are bad at generating them. We have biases towards certain numbers by conscious (or unconscious!) recognition of those numbers. But it turns out that computers have just as hard a time as we do! Computers are designed to be deterministic, so generating random numbers can be quite difficult. To do it, various algorithms have been written to generate numbers from some distribution, but fed with a random 'seed' to spit out that number. This seed is typically a signed 32-bit integer (of the range -2147483648 to 2147483648), but realistically any size or type can be used (and 64-bit integers are becoming increasingly common as the range of possible values is massive). 

But how do you generate a seed? 
With another random number generator. Which must have come from some deterministic process. 
So no matter how many generators you have generating seeds for your random output, you can always go back to a deterministic value that seeded it all. It isn't ever truly random, just pseudo-random. Of course, certain trickery has allowed for more complex randomness: some of the latest has to do with quantum mechanics of a laser reflecting or absorbing photons and treating the output of the number absorbed vs reflected as a random number, which is theoretically truly random. But do you really need a laser to seed a pseudo-random process? Or a system of lava lamps (a la [CloudFlare](https://www.youtube.com/watch?v=1cUUfMeOijg))? Probably not. As long as you are blind to the original seed that created your random numbers, it might as well be random: the chance that you are going to be able to find that original seed quite often exceeds the number of atoms in the observable universe (SOURCE). ```/dev/random```, which we saw in Box 2.1.1, generates random numbers based on environmental noise from your computer hardware drivers, which is supposedly close to 'true' randomness. [But is 'true' randomness a thing at all](https://en.wikipedia.org/wiki/Determinism)? Is the universe deterministic? What is the universe's seed? If you put the universe's seed into a Minecraft world generator, would that world have many diamonds? 
Food for thought.

The point is that you should be careful with generating random numbers and make sure you know that the ultimate source of randomness is as close to 'true' random as possible, but if it isn't, as long as it is secure and probabilistically close to impossible to crack, it is probably a good enough source of randomness for whatever you are trying to do.
::::

OK, so we can run SLiM via the command line for a single seed or variable combination. Now we could run that command multiple times, changing the seed or parameters manually every time we run it, but that's inefficient and makes it difficult to use all your available resources on your computer (notably, cores for running separate SLiM instances in parallel). This is where sublaunching scripts can come in handy. These enable us to use a pre-written script to vary all the parameters we would like automatically, and run many SLiM experiments at once as possible.

As a quick aside, these template scripts I'm providing require a ```seeds.csv``` file to be in the format of a single column with a header called 'Seed'. My SeedGenerator program which I have provided (Under "Tools" in the [main GitHub branch](https://github.com/nobrien97/PolygenicSLiMBook)), (along with an install script) will generate these for you. To use SeedGenerator, simply run ```seedgen_install.sh```, and then ```./seedgenerator```. There are a variety of options, listed with the -h or --help flag:

```{bash seedgen}
# Shows the help file with instructions on each of the options
 ../Tools/SeedGenerator/seedgenerator --help
```

Now onto sublaunching SLiM. We'll start with Bash, which is perhaps the simplest.


## 6.3 Running SLiM via Bash

The simplest way to run SLiM at the command line is through Bash, the standard command line scripting language of Linux based systems. Note that the SLiM Online Workshop - '_Running SLiM from the command line_' tutorial goes over much of what I'll be presenting below.
The Bash syntax is pretty similar to the standard way of running SLiM on the command line, and in fact you'll be using almost identical commands.

```{bash slim_sub_bash1, eval = F}
for seed in seeds.csv; do
  echo "Running with seed == " $(seed):
  slim -s $(seed) ~/Desktop/example_script.slim &
  echo 
done
```

Here, we do a simple for loop over the seeds in a file called seeds.csv (generated by Tools/SeedGenerator/seedgenerator). For this to work in bash, make sure you have the header disabled (```./seedgenerator -t```)
The ```&``` character tells Bash to run the slim process as a background task, meaning it is put on an available core. This results in SLiM processes running parallelised across multiple cores!

Bash can also be used to parallelise over many parameters, but it quickly becomes difficult to read. For example, here is an example script with two parameters and a seed variable:

```{bash slim_sub_bash2, eval=F}
for param1 in 0.1 0.2 0.3
  do
  for param2 in "Low" "Medium" "High"
    do
    for seed in seeds.csv
      do
      echo "Seed = " $(seed) " param1 = " $(param1) " param2 = " $(param2):
      slim -s $(seed) -d param1=$(param1) -d param2=$(param2) ~/Desktop/example_script.slim &
      echo
      done
    done
  done

```

While it is also possible to read in files and split columns into different variables, it's much easier to do this in R or Python. So for more complex scripts, I would highly suggest using either of those to sublaunch your SLiM jobs. I will provide examples of both below.

## 6.4 Running SLiM via R

This is how I normally sublaunch SLiM. R has a variety of packages that make it easy to parallelise across cores, and because of R's rich feature set and the breadth of user-made libraries, the options are endless when it comes to feeding parameters to SLiM, loading output, or integrating with SLiM.

``` {r slim_sub_r1, eval = F}

# Parallelisation libraries 

library(foreach)
library(doParallel)
library(future)


seeds <- read.csv("~/Desktop/seeds.csv", header = T)


cl <- makeCluster(future::availableCores())
registerDoParallel(cl)

#Run SLiM

foreach(i=seeds$Seed) %dopar% {
	# Use string manipulation functions to configure the command line args, feeding from a data frame of seeds
	# then run SLiM with system(),
    	slim_out <- system(sprintf("/home/$USER/SLiM/slim -s %s ~/Desktop/example_script.slim", as.character(i), intern=T))
  }
stopCluster(cl)

```

This script first loads a series of libraries that allow R to run a for loop across multiple cores. Each iteration of the for loop is assigned to a free core when it becomes available. We then load in ```seeds.csv``` as a dataframe, and set up a local 'cluster', which basically lets R know how many cores are available on your system that it can use. The seeds are then fed into our for loop (```foreach```, which is implemented specifically to be parallel). For each seed, we run the for loop, with the ```%dopar%``` operator saying that we should do those iterations across as many cores as are available. The ```system()``` command tells the operating system to run a command, given as a string. ```sprintf()``` creates a string from its inputs, with support for variables to be added to the string on the fly. This is done with the ```%``` symbol followed by the type that is being fed to ```sprintf()```. For example, ```%s```  provides a placeholder for a string variable. These variables are listed at the end of the line _in the order that they are mentioned in the ```sprintf()``` command. For example, here ```%s```, being the first variable mentioned in the string, is replaced by the first variable mentioned after the string ends with the closing \". In this case, we feed SLiM a seed with the ```-s``` command, replacing ```%s``` with ```as.character(i)```, which is the seed given by the for loop. 
As well as ```%s```, there is also ```i``` and ```f``` for integer and floating point (or double, since R only supports doubles) numbers. 
So why do we feed SLiM a string as a seed instead of an integer? It's to ensure it gets read properly. R only supports signed 32-bit integers, which are a fair bit smaller than SLiM's 64-bit integers. Since the idea of randomly choosing seeds is to uniformly sample across the entire range of possible values to avoid any kind of correlations, we sample across the range of 64 bit values. However, R can't handle numbers so big as integers, so it automatically coerces them to doubles. Doubles are stored in computers very differently to integers, and having R treat this number as an integer (or as a float) and then feed it to SLiM that way results in unexpected behaviour. I've found it's safest to just treat the seed as a string so no coercion happens - SLiM automatically will treat that string as an integer when it is loaded anyway. 

Now, the R script is a little more complex at base-level than a Bash script, but I find it much easier to expand upon. Say for example we have two parameters as before. We could use nested ```foreach``` loops just like we did in Bash, but it's easier to exploit R's dataframe support to have a dataframe of possible parameter combinations, and then use each iteration to choose the right combination. This way, we simply need one level of nesting regardless of how many parameters we have: one ```foreach``` loop for seeds, and a nested one for parameter combinations.
``` {r slim_sub_r2, eval = F}

# Create a list of parameters
p <- list()
p$param1 <- c(0.1, 0.2, 0.3)
p$param2 <- c('"Low"', '"Medium"', '"High"') #'" is necessary for SLiM to read them as strings

# Save the list as a data frame with all possible combinations
df.p <- expand.grid(p)

# You can also save df.p as a csv file and import it later, as with seeds: write.csv(df.p, row.names = F)

# Now we can use those data frame rows as inputs for our script

# Parallelisation libraries 

library(foreach)
library(doParallel)
library(future)


seeds <- read.csv("~/Desktop/seeds.csv", header = T)


cl <- makeCluster(future::availableCores())
registerDoParallel(cl)

#Run SLiM
foreach(i=1:nrow(df.p)) %:%
  foreach(j=seeds$Seed) %dopar% {
    	slim_out <- system(sprintf("/home/$USER/SLiM/slim -s %s -d param1=%f -d param2=%s  ~/Desktop/example_script.slim", as.character(j), df.p[i,]$param1, df.p[i,]$param2, intern=T))
  }
stopCluster(cl)

```

Here we do the exact thing as before: creating a local cluster and running a ```foreach``` loop. However, in this case we nest a second ```foreach``` loop so we can include both seeds and the parameter combinations. Each ```i``` in this loop is a different row in the ```df.p``` dataframe of parameter combinations. Each ```j``` is a different seed. Notice we only ues ```%dopar%``` once, and use that on the innermost ```foreach``` loop. This means for each parameter combination (```i```), we will parallelise across seeds (```j```). This can be extended to as many parameter values as you want, as we simply fill each parameter using the ```sprintf()``` variable-filling functionality as before, this time referencing ```df.p``` and choosing the appropriate column (parameter value).

## 6.5 Running SLiM in Python

Running SLiM in Python is similarly straightforward, and due to its plethora of libraries, quite powerful also.
Here's an example

```{python slim_sub_py1, eval = F}
from os import system
from multiprocessing import Pool
from pandas import read_csv

# Open the seeds file

seeds = read_csv(r'../Inputs/seeds.csv')

# Open a new 'pool' - like makeCluster() in R

cluster = Pool()

# Do an operation on the pool - this is like foreach() in R

def slim_call(seed):
    system('slim -s {} ~/Desktop/example_script.slim'.format(seed)) 

cluster.map(slim_call, seeds['Seed'].tolist())

cluster.close()
cluster.join()
```

In this script, we iterate over seeds only, using the built-in ```os``` and ```multiprocessing``` libraries, and the popular ```pandas``` library.
To install pandas, run ```python -m pip install pandas``` in a Terminal and restart Python if you have it open.

We first use the ```pandas``` function ```read_csv()``` to load our seeds into a dataframe. From there we create a new pool - this is analogous
to creating a new cluster with ```makeCluster()``` in R. The default setting as shown creates a pool with all available cores, however using 
```Pool(x)``` where x is the number of cores you would like to use. 
We define a function to call slim via the ```os.system()``` command, and use our Pool's own function ```map``` to map a list of imputs to our SLiM
function. This will run the function for all values in that vector, and on as many cores available to the Pool.
Using ```cluster.close()``` followed by ```cluster.join()``` is good practice, just like closing the cluster in R with ```stopCluster()```


Now lets expand this to our list of combinations like in R:

```{python, slim_sub_py2, eval = F}
from os import system
from multiprocessing import Pool
from itertools import product
from pandas import read_csv, DataFrame
from joblib import Parallel, delayed

# Open the seeds file as a list

seeds = read_csv(r'../Inputs/seeds.csv')['Seed'].to_list()

# Create a list of parameters and generate unique combinations
param1 = [0.1, 0.2, 0.3]
param2 = ['Low', 'Medium', 'High']
p = {'param1' : [0.1, 0.2, 0.3], 'param2' : ['Low', 'Medium', 'High']}
keys, values = zip(*p.items())
# https://stackoverflow.com/a/61335465/13586824
combos = [dict(zip(keys, v)) for v in product(*values)]
combos = DataFrame.from_dict(combos)


# Open a new 'pool' - like makeCluster() in R

cluster = Pool()

# Do an operation on the pool - this is like foreach() in R

def slim_call(parameters):
    for seed in seeds:
        system('slim -s {se} -d param1={p1} -d param2={p2} ~/Desktop/example_script.slim'.format(se=seed, p1=parameters['param1'], p2=parameters['param2'])) 

seeds['Seed'].to_list()

cluster.starmap(slim_call, combos)
cluster.close()
cluster.join()

```

Here, we encapsulate our SLiM call in a function which includes a for loop over seeds. We then use the ```Pool.starmap()``` function to run in parallel these SLiM runs across combinations. Indeed, this ordering could also be reversed so that the for loop contains the combinations and ```starmap()``` iterates over seeds. This might be a good idea if the number of combinations is less than the number of seeds, to leverage as much parallel power as possible and reduce wasted time.


